{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "49986d52",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "from scipy.stats import multivariate_normal"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "851dbc0c",
   "metadata": {},
   "source": [
    "Log:\n",
    "\n",
    "- 11/10 Fixed bugs: H^(-1/2) formula, shapes of theta & epsilons\n",
    "- 11/10 Updated codes to reduce sampling time"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "90f128fb",
   "metadata": {},
   "source": [
    "# Functions to be tested"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "15882cc0",
   "metadata": {},
   "source": [
    "For now, use a very simple function - quadratic with max value 0, and theta* = [0.5, 0.5] \n",
    "\n",
    "Also note that we will maximize the function, not minimize."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "id": "cd55958c",
   "metadata": {},
   "outputs": [],
   "source": [
    "def F(theta):\n",
    "    if theta.ndim == 1:\n",
    "        theta = np.expand_dims(theta, 0)\n",
    "    return -np.sum((theta - 0.5) ** 2, axis=tuple(range(theta.ndim)[1:]))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a29be582",
   "metadata": {},
   "source": [
    "# Gradient benchmark\n",
    "\n",
    "This is exactly the Algorithm 1 in the RL paper."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "id": "89b65c3e",
   "metadata": {},
   "outputs": [],
   "source": [
    "def ES_benchmark_gradient(alpha, sigma, theta_0, num_samples, time_steps):\n",
    "    d = theta_0.shape[0]\n",
    "    theta_t = theta_0\n",
    "    n = num_samples\n",
    "    for t in range(time_steps):\n",
    "        #**** sample epsilons ****#\n",
    "        epsilons = np.random.multivariate_normal(mean = np.zeros(d), cov = np.identity(d), size = n) # n by d\n",
    "        #**** compute function values ****#\n",
    "        F_list = []\n",
    "        for i in range(n):\n",
    "            F_val = F(theta_t + sigma * epsilons[i])\n",
    "            F_list.append(F_val)\n",
    "        #**** update theta ****#\n",
    "        new_theta = theta_t\n",
    "        for i in range(n):\n",
    "            new_theta += alpha / (n*sigma) * F_list[i] * epsilons[i] \n",
    "        theta_t = new_theta\n",
    "    return theta_t, F(theta_t)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "id": "83a7e4ae",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(array([0.49979673, 0.50081561]), array([-7.06536921e-07]))"
      ]
     },
     "execution_count": 69,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "ES_benchmark_gradient(alpha=1e-3, sigma=0.1, theta_0 = np.array([1.0,1.0]), num_samples = 50, time_steps = 5000)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e8857f6f",
   "metadata": {},
   "source": [
    "# HessAware Benchmark"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "73023572",
   "metadata": {},
   "source": [
    "This implements the Hess Aware algorithm in Zhang's paper. \n",
    "\n",
    "The Hessian estimate comes from Section 4.1."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "id": "b360c39c",
   "metadata": {},
   "outputs": [],
   "source": [
    "def ES_benchmark_hess_aware(alpha, sigma, theta_0, num_samples, time_steps, p, H_lambda):\n",
    "    d = theta_0.shape[0]\n",
    "    theta_t = theta_0.reshape((d,1))\n",
    "    n = num_samples\n",
    "    H = None\n",
    "    for t in range(time_steps):\n",
    "        #**** sample epsilons ****#\n",
    "        epsilons = np.random.multivariate_normal(mean = np.zeros(d), cov = np.identity(d), size = n) # n by d\n",
    "        #**** compute function values ****#\n",
    "        F_plus_list = []; F_minus_list = []; F_list = []\n",
    "        for i in range(n):\n",
    "            F_plus_list.append(F(theta_t + sigma * epsilons[i].reshape((d,1))))\n",
    "            F_minus_list.append(F(theta_t - sigma * epsilons[i].reshape((d,1))))\n",
    "            F_list.append(F(theta_t))\n",
    "        #**** compute Hessian every p steps ****#\n",
    "        if t % p == 0:\n",
    "            H = np.zeros((d,d))\n",
    "            for i in range(n):\n",
    "                e_i = epsilons[i].reshape((d,1))\n",
    "                e_i_trans = np.transpose(e_i)\n",
    "                H += (F_plus_list[i] + F_minus_list[i] - 2*F_list[i]) * (e_i @ e_i_trans)\n",
    "            H /= 2*(sigma**2)*n\n",
    "            H += H_lambda * np.identity(d)\n",
    "        #**** update theta: compute g ****#\n",
    "        u, s, vh = np.linalg.svd(H)\n",
    "        H_nh = u @ np.diag(s**-0.5) @ vh\n",
    "        g = 0\n",
    "        for i in range(n):\n",
    "            e_i = epsilons[i].reshape((d,1))\n",
    "            F_new = F(theta_t +  sigma* (H_nh @ e_i)  )\n",
    "            g += ((F_new - F(theta_t)) / sigma ) * (H_nh @ e_i) / n\n",
    "        #**** update theta: the rest ****#\n",
    "        new_theta = theta_t + alpha * g\n",
    "        theta_t = new_theta\n",
    "        \n",
    "    return theta_t, F(theta_t), H"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "id": "1c426c74",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(array([[0.05275927, 0.96918208],\n",
       "        [0.96885678, 0.05579611]]),\n",
       " array([-0.42015609, -0.41714377]),\n",
       " array([[-6.05413759, -0.22772953],\n",
       "        [-0.49210759, -4.71143407]]))"
      ]
     },
     "execution_count": 71,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "ES_benchmark_hess_aware(alpha=0.1, sigma=0.01, theta_0=np.array([1.0,1.0]), num_samples = 1000, time_steps = 100, p = 10, H_lambda = 0)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "21a41f04",
   "metadata": {},
   "source": [
    "# First Hessian-based method\n",
    "\n",
    "We use the Hessian estimate as in the write-up document on Overleaf.\n",
    "\n",
    "Then, the same Newton's method as in Zhang's paper is used to update theta with the Hessian estimate.\n",
    "\n",
    "As before, alpha is the learning rate. The parameter p defines how often we re-compute the Hessian."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 240,
   "id": "b344b4a2",
   "metadata": {},
   "outputs": [],
   "source": [
    "delta_g_lst = []\n",
    "diag_lst = []\n",
    "def ES_hessian(alpha, sigma, theta_0, num_samples, time_steps, p, H_lambda):\n",
    "    d = theta_0.shape[0]\n",
    "    theta_t = theta_0\n",
    "    n = num_samples\n",
    "    H = None\n",
    "    for t in range(time_steps):\n",
    "        #**** sample epsilons ****#\n",
    "        epsilons = np.random.multivariate_normal(mean = np.zeros(d), cov = np.identity(d), size = n) # n by d\n",
    "        #**** compute Hessian every p steps ****#\n",
    "        if t % p == 0:\n",
    "            Fs = F(theta_t + sigma*epsilons)\n",
    "            eps = np.expand_dims(epsilons, -1)\n",
    "            H_samples = ((eps*np.transpose(eps, (0, 2, 1)) - np.identity(d))* Fs.reshape(-1, 1, 1))/(sigma**2)\n",
    "            H = H_samples.mean(axis=0)\n",
    "        #**** update theta: compute g ****#\n",
    "        u, s, vh = np.linalg.svd(H)\n",
    "        H_nh = u @ np.diag(s**-0.5) @ vh\n",
    "        H_nh_3d = np.ones((n, d, d)) * H_nh\n",
    "        Fs = F(theta_t +  sigma* np.transpose((H_nh @ np.transpose(epsilons) )) ) - F(theta_t)\n",
    "        eps = np.expand_dims(epsilons, -1)\n",
    "        g_samples =  H_nh_3d @ eps * Fs.reshape(-1, 1, 1)/sigma\n",
    "        g = g_samples.mean(axis=0).ravel()\n",
    "        \n",
    "        #**** update theta: the rest ****#\n",
    "        new_theta = theta_t + alpha * g\n",
    "        theta_t = new_theta\n",
    "        \n",
    "    return theta_t, F(theta_t), H"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 252,
   "id": "6f9eb486",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(array([0.48280216, 0.4788555 ]), array([-0.00074286]), array([[-2.42753549, -0.1397509 ],\n",
      "       [-0.1397509 , -2.20456166]]))\n"
     ]
    }
   ],
   "source": [
    "res = ES_hessian(alpha=0.5, sigma=0.5, theta_0=np.array([1.0,1.0]), num_samples = 1000, time_steps = 1000, p = 10, H_lambda = 0)\n",
    "print(res)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a9296935",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
