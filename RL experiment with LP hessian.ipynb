{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "22c7abca",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import cvxpy as cp\n",
    "import gym\n",
    "import matplotlib.pyplot as plt\n",
    "from numpy.linalg import LinAlgError\n",
    "\n",
    "\n",
    "import sys\n",
    "sys.path.append('./asebo/')\n",
    "from optimizers import Adam\n",
    "from worker import worker, get_policy\n",
    "from es import ES"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "81ac3f96",
   "metadata": {},
   "outputs": [],
   "source": [
    "def F(theta):\n",
    "    if theta.ndim == 1:\n",
    "        theta = np.expand_dims(theta, 0)\n",
    "    return -np.sum((theta - 0.5) ** 2, axis=tuple(range(theta.ndim)[1:]))\n",
    "\n",
    "\n",
    "def Gradient_LP(y, epsilons):\n",
    "    \"\"\"\n",
    "    y = (F(theta + sigma*epsilons) - F(theta)) / sigma\n",
    "    epsilons: the perturbations with UNIT VARIANCE\n",
    "    \"\"\"\n",
    "    n, d = epsilons.shape\n",
    "    \n",
    "    var_z = cp.Variable(n)\n",
    "    var_g = cp.Variable(d)\n",
    "    obj = sum(var_z)\n",
    "    constraints = [var_z >= y - epsilons @ var_g,\n",
    "                   var_z >= -y + epsilons @ var_g]\n",
    "    prob = cp.Problem(cp.Minimize(obj), constraints)\n",
    "    prob.solve(solver=cp.GLPK, eps=1e-6, glpk={'msg_lev': 'GLP_MSG_OFF'})\n",
    "    if prob.status == 'optimal':\n",
    "        return var_g.value\n",
    "    return None\n",
    "\n",
    "def Hessian_LP(y, epsilons):\n",
    "    \"\"\"\n",
    "    y = (F(theta + sigma*epsilons) + F(theta - sigma*epsilons) - 2*F(theta)) / (sigma**2)\n",
    "    epsilons: the perturbations with UNIT VARIANCE\n",
    "    \"\"\"\n",
    "    n, d = epsilons.shape\n",
    "    \n",
    "    \n",
    "    X = np.zeros((n, d*(d+1)//2))\n",
    "    idx = 0\n",
    "    for j in range(d):\n",
    "        X[:,idx] = epsilons[:,j]**2\n",
    "        idx += 1\n",
    "        if j == d-1:\n",
    "            break\n",
    "        X[:,idx:idx+d-j-1] = 2 * epsilons[:,j:j+1] * epsilons[:,j+1:]\n",
    "        idx += d-j-1\n",
    "#         X[:,j*(j+1)//2:(j+1)*(j+2)//2-1] = 2 * epsilons[:,j:j+1] * epsilons[:,:j]\n",
    "#         X[:,(j+1)*(j+2)//2-1] = epsilons[:,j]**2\n",
    "    \n",
    "    var_z = cp.Variable(n)\n",
    "    var_H = cp.Variable(d*(d+1)//2)\n",
    "    \n",
    "    obj = sum(var_z)\n",
    "    \n",
    "    constraints = []\n",
    "    for i in range(n):\n",
    "        constraints += [var_z[i] >= y[i] - X[i] @ var_H]\n",
    "        constraints += [var_z[i] >= - y[i] + X[i] @ var_H]\n",
    "    \n",
    "    prob = cp.Problem(cp.Minimize(obj), constraints)\n",
    "    prob.solve(solver=cp.GLPK, eps=1e-6, glpk={'msg_lev': 'GLP_MSG_OFF'})\n",
    "\n",
    "    if prob.status == 'optimal':\n",
    "        H = np.zeros((d,d))\n",
    "        idx = 0\n",
    "        for j in range(d):\n",
    "            H[j,j:] = var_H[idx:idx+d-j].value\n",
    "            H[j:,j] = var_H[idx:idx+d-j].value\n",
    "            idx += d-j\n",
    "#             H[j,0:j+1] = var_H[j*(j+1)//2:(j+1)*(j+2)//2].value\n",
    "#             H[1:j+1,j] = H[j,1:j+1]\n",
    "        return H\n",
    "    return None\n",
    "\n",
    "\n",
    "def get_dct_mtx(d):\n",
    "    # DCT matrix\n",
    "    # unitary, symmetric and real\n",
    "    # Orthonormal eigenbasis for structured H\n",
    "    n = 2*d\n",
    "    i_idx = np.array([range(n//2 )])\n",
    "    idx = 2 * np.transpose(i_idx) @ i_idx\n",
    "    dct_mtx = np.cos(idx*np.pi / n) * 2 / np.sqrt(d)\n",
    "    dct_mtx[0,0] = 1\n",
    "    dct_mtx[0,d-1] = 1\n",
    "    dct_mtx[d-1,0] = 1\n",
    "    dct_mtx[d-1,d-1] = (-1)**(d)\n",
    "    return dct_mtx\n",
    "def Hessian_LP_structured(y, epsilons):\n",
    "    \"\"\"\n",
    "    y = (F(theta + sigma * epsilons) + F(theta - sigma * epsilons) - 2 * F(theta)) / (sigma ** 2)\n",
    "    \"\"\"\n",
    "    # LP formulation to estimate Hessian\n",
    "    # Minimizing over the space of matrices of the form\n",
    "    # shown in the example 7 & 8 in the reference\n",
    "    # [MATRICES DIAGONALIZED BY THE DISCRETECOSINE AND DISCRETE SINE TRANSFORMS]\n",
    "    \n",
    "    n, d = epsilons.shape\n",
    "    \n",
    "    # Define and solve the LP for Hessian here\n",
    "    var_z = cp.Variable(n)\n",
    "    var_H_diag = cp.Variable(d)\n",
    "    \n",
    "    # Lower triangular mtx H\n",
    "    dct_mtx = get_dct_mtx(d)\n",
    "    obj = sum(var_z)\n",
    "    \n",
    "    constraints = []\n",
    "    for i in range(n):\n",
    "        Uv = epsilons[i:i+1,:] @ dct_mtx\n",
    "        Uv_sq = Uv * Uv\n",
    "        constraints += [var_z[i] >= y[i] - Uv_sq @ var_H_diag]\n",
    "        constraints += [var_z[i] >= - y[i] + Uv_sq @ var_H_diag]\n",
    "    for i in range(d):\n",
    "        constraints += [var_H_diag[i] <= 0]\n",
    "        \n",
    "    prob = cp.Problem(cp.Minimize(obj), constraints)\n",
    "    prob.solve(solver=cp.GLPK, eps=1e-6, glpk={'msg_lev': 'GLP_MSG_OFF'})\n",
    "    \n",
    "    # \n",
    "    if prob.status == 'optimal':\n",
    "        return dct_mtx @ np.diag(var_H_diag.value) @ np.transpose(dct_mtx)\n",
    "    \n",
    "    return None\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "id": "4cc9408c",
   "metadata": {},
   "outputs": [],
   "source": [
    "def aggregate_rollouts_hessianES(master, A, params, n_samples):\n",
    "    \n",
    "    all_rollouts = np.zeros([n_samples+1, 2])\n",
    "\n",
    "    timesteps = 0\n",
    "    \n",
    "    # F(theta + sigma*epsilons), and F(theta - sigma*epsilons)\n",
    "    assert A.shape[0] == n_samples+1\n",
    "    for i in range(n_samples+1):\n",
    "        w = worker(params, master, A, i)\n",
    "        all_rollouts[i] = np.reshape(w.do_rollouts(), 2)\n",
    "        timesteps += w.timesteps\n",
    "\n",
    "    all_rollouts = (all_rollouts - np.mean(all_rollouts)) / (np.std(all_rollouts)  + 1e-8)\n",
    "    \n",
    "    # (F(theta + sigma*epsilons) - F(theta)) / sigma\n",
    "    gradient_y = np.array(all_rollouts[:-1, 0] - sum(all_rollouts[-1])/2) / params[\"sigma\"]\n",
    "    # (F(theta + sigma*epsilons) + F(theta - sigma*epsilons) - 2*F(theta)) / (sigma**2)\n",
    "    hessian_y = np.array(all_rollouts[:-1, 0] + all_rollouts[:-1, 1] - sum(all_rollouts[-1])) / (params[\"sigma\"]**2)\n",
    "    return(gradient_y, hessian_y, timesteps)\n",
    "\n",
    "def HessianES(params, master):\n",
    "        \n",
    "#     if params['n_iter'] >= params['k']:\n",
    "#         pca = PCA()\n",
    "#         pca_fit = pca.fit(G)\n",
    "#         var_exp = pca_fit.explained_variance_ratio_\n",
    "#         var_exp = np.cumsum(var_exp)\n",
    "#         n_samples = np.argmax(var_exp > params['threshold']) + 1\n",
    "#         if n_samples < params['min']:\n",
    "#             n_samples = params['min']\n",
    "#         U = pca_fit.components_[:n_samples]\n",
    "#         UUT = np.matmul(U.T, U)\n",
    "#         U_ort = pca_fit.components_[n_samples:]\n",
    "#         UUT_ort = np.matmul(U_ort.T, U_ort)\n",
    "#         alpha = params['alpha']\n",
    "#         if params['n_iter'] == params['k']:\n",
    "#             n_samples = params['num_sensings']\n",
    "#     else:\n",
    "#         UUT = np.zeros([master.N, master.N])\n",
    "#         alpha = 1\n",
    "#         n_samples = params['num_sensings']\n",
    "    \n",
    "    n_samples = params['num_sensings']\n",
    "    \n",
    "#     np.random.seed(None)\n",
    "    cov = np.identity(master.N)*(params[\"sigma\"]**2)\n",
    "    mu = np.repeat(0, master.N)\n",
    "    A = np.random.multivariate_normal(mu, cov, n_samples)\n",
    "#     A /= np.linalg.norm(A, axis =-1)[:, np.newaxis]\n",
    "    A = np.vstack([A, mu]) # Adding a reference evaluation\n",
    "        \n",
    "    gradient_y, hessian_y, timesteps = aggregate_rollouts_hessianES(master, A, params, n_samples)\n",
    "    \n",
    "    g = Gradient_LP(gradient_y, A[:-1, :]/params[\"sigma\"])\n",
    "#     H = Hessian_LP(hessian_y, A[:-1, :]/params[\"sigma\"])#-0.1*np.identity(master.N)\n",
    "    H = Hessian_LP_structured(hessian_y, A[:-1, :]/params[\"sigma\"]) - 0.1*np.identity(master.N)\n",
    "#     H = -np.identity(len(g))\n",
    "    try:\n",
    "        Hinv = True\n",
    "        update_direction = -np.linalg.inv(H)@g\n",
    "    except LinAlgError:\n",
    "        Hinv = False\n",
    "        update_direction = g\n",
    "#     if params['n_iter'] >= params['k']:\n",
    "#         params['alpha'] = np.linalg.norm(np.dot(g, UUT_ort))/np.linalg.norm(np.dot(g, UUT))\n",
    "    \n",
    "    return(update_direction, n_samples, timesteps, Hinv)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2475115c",
   "metadata": {},
   "source": [
    "## Manuel Tests"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "id": "a2df76dc",
   "metadata": {},
   "outputs": [],
   "source": [
    "params = {\n",
    "# 'env_name': 'InvertedPendulum-v2',\n",
    "'env_name': 'InvertedDoublePendulum-v2',\n",
    "'steps':1000,\n",
    "'h_dim':8,\n",
    "'start':0,\n",
    "'max_iter':1000,\n",
    "'seed':0,\n",
    "\n",
    "'k':140,\n",
    "'num_sensings':100,#100\n",
    "'log':0,\n",
    "'threshold':0.995,\n",
    "'decay':0.99,\n",
    "'learning_rate':0.05,#0.05\n",
    "'filename':'',\n",
    "'policy':'Linear', # Linear or Toeplitz\n",
    "\n",
    "'shift':0,\n",
    "'min':10,\n",
    "'sigma':1\n",
    "}\n",
    "\n",
    "params['dir'] = params['env_name'] + params['policy'] + '_h' + str(params['h_dim']) + '_lr' + str(params['learning_rate']) + '_num_sensings' + str(params['num_sensings']) +'_' + params['filename']\n",
    "\n",
    "# if not(os.path.exists('data/'+params['dir'])):\n",
    "#     os.makedirs('data/'+params['dir'])\n",
    "# os.chdir('data/'+params['dir'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "id": "c8114bb8",
   "metadata": {},
   "outputs": [],
   "source": [
    "env = gym.make(params['env_name'])\n",
    "params['ob_dim'] = env.observation_space.shape[0]\n",
    "params['ac_dim'] = env.action_space.shape[0]\n",
    "\n",
    "m = 0\n",
    "v = 0\n",
    "\n",
    "params['k'] += -1\n",
    "params['alpha'] = 1\n",
    "\n",
    "params['zeros'] = False\n",
    "master = get_policy(params)\n",
    "\n",
    "if params['log']:\n",
    "    params['num_sensings'] = 4 + int(3 * np.log(master.N))\n",
    "\n",
    "if params['k'] > master.N:\n",
    "    params['k'] = master.N\n",
    "\n",
    "n_eps = 0\n",
    "n_iter = 1\n",
    "ts_cumulative = 0\n",
    "ts = []\n",
    "rollouts = []\n",
    "rewards = []\n",
    "samples = []\n",
    "alphas = []\n",
    "G = [] # Don't need this for HessianES\n",
    "Hinv_success = 0\n",
    "\n",
    "n_samples = params['num_sensings']+200\n",
    "# np.random.seed(None)\n",
    "cov = np.identity(master.N)*(params[\"sigma\"]**2)\n",
    "mu = np.repeat(0, master.N)\n",
    "A = np.random.multivariate_normal(mu, cov, n_samples)\n",
    "A /= np.linalg.norm(A, axis =-1)[:, np.newaxis]\n",
    "A = np.vstack([A, mu]) # Adding a reference evaluation\n",
    "\n",
    "gradient_y, hessian_y, timesteps = aggregate_rollouts_hessianES(master, A, params, n_samples)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "id": "d06b757f",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(301, 11)"
      ]
     },
     "execution_count": 50,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "A.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "id": "0421ec99",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CPU times: user 159 ms, sys: 2.58 ms, total: 162 ms\n",
      "Wall time: 161 ms\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "g = Gradient_LP(gradient_y, A[:-1, :]/params[\"sigma\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "id": "1de382d4",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CPU times: user 786 ms, sys: 4.71 ms, total: 791 ms\n",
      "Wall time: 790 ms\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "Hstruc = Hessian_LP_structured(hessian_y, A[:-1, :]/params[\"sigma\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "id": "bf519af5",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.],\n",
       "       [0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.],\n",
       "       [0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.],\n",
       "       [0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.],\n",
       "       [0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.],\n",
       "       [0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.],\n",
       "       [0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.],\n",
       "       [0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.],\n",
       "       [0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.],\n",
       "       [0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.],\n",
       "       [0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.]])"
      ]
     },
     "execution_count": 53,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "Hstruc"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "id": "dfc520f6",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(array([0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.]),\n",
       " array([[1., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.],\n",
       "        [0., 1., 0., 0., 0., 0., 0., 0., 0., 0., 0.],\n",
       "        [0., 0., 1., 0., 0., 0., 0., 0., 0., 0., 0.],\n",
       "        [0., 0., 0., 1., 0., 0., 0., 0., 0., 0., 0.],\n",
       "        [0., 0., 0., 0., 1., 0., 0., 0., 0., 0., 0.],\n",
       "        [0., 0., 0., 0., 0., 1., 0., 0., 0., 0., 0.],\n",
       "        [0., 0., 0., 0., 0., 0., 1., 0., 0., 0., 0.],\n",
       "        [0., 0., 0., 0., 0., 0., 0., 1., 0., 0., 0.],\n",
       "        [0., 0., 0., 0., 0., 0., 0., 0., 1., 0., 0.],\n",
       "        [0., 0., 0., 0., 0., 0., 0., 0., 0., 1., 0.],\n",
       "        [0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 1.]]))"
      ]
     },
     "execution_count": 54,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "np.linalg.eig(Hstruc)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "id": "3c22320e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CPU times: user 1.02 s, sys: 13.2 ms, total: 1.04 s\n",
      "Wall time: 1.04 s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "H = Hessian_LP(hessian_y, A[:-1, :]/params[\"sigma\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "id": "eab817de",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(11, 11)"
      ]
     },
     "execution_count": 56,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "H.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "id": "1e2d6178",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(array([ 5.54529529, -2.88300251,  1.02019975, -0.85271169, -0.64320833,\n",
       "         0.52638407,  0.48230831,  0.31038016, -0.11536853,  0.02823345,\n",
       "         0.08519172]),\n",
       " array([[ 2.23390725e-02,  3.63937228e-02,  9.62646048e-03,\n",
       "          2.36568066e-02, -2.75866216e-02, -1.80773563e-01,\n",
       "         -3.76259224e-01, -5.90301367e-01,  4.67709135e-01,\n",
       "          4.54464097e-01,  2.20834527e-01],\n",
       "        [-2.48164043e-02, -1.15013590e-01, -1.22580185e-01,\n",
       "          1.07831726e-01,  5.69345083e-01,  2.24963910e-01,\n",
       "          4.88878309e-01, -3.17794748e-01, -1.54833121e-01,\n",
       "          5.60885177e-02,  4.66503090e-01],\n",
       "        [ 3.85236403e-02,  5.86577713e-02,  8.63316832e-02,\n",
       "          5.30649221e-01, -1.98509448e-01,  7.59138984e-02,\n",
       "          2.51541529e-01,  5.10160441e-01,  2.79569183e-01,\n",
       "          4.46099782e-01,  2.45283021e-01],\n",
       "        [ 1.27808863e-01, -6.76439958e-01,  3.65455488e-01,\n",
       "          7.66422619e-02, -1.25271218e-01, -5.12402042e-01,\n",
       "          2.22139257e-02, -1.02794600e-02, -2.58352889e-01,\n",
       "         -2.80952150e-03,  2.02633072e-01],\n",
       "        [ 1.69803193e-01, -6.75380255e-01, -4.06735029e-01,\n",
       "         -7.54724915e-02,  4.33053121e-02,  4.40954045e-01,\n",
       "         -2.20100833e-01,  1.50049688e-01,  2.56755859e-01,\n",
       "          3.24694779e-02, -9.82138620e-02],\n",
       "        [ 1.39913462e-01, -5.97814825e-02,  1.51363783e-01,\n",
       "         -3.37866565e-02,  7.11071213e-02,  1.40464682e-01,\n",
       "          1.77907868e-01, -1.58489387e-01, -3.36420376e-01,\n",
       "          6.34185892e-01, -5.96549080e-01],\n",
       "        [-5.25743060e-01, -4.63404579e-02, -5.53121755e-01,\n",
       "         -2.73185275e-02, -3.57181953e-01, -1.03682167e-01,\n",
       "         -4.91685279e-02, -1.67706492e-02, -4.17450181e-01,\n",
       "          2.60531098e-01,  1.77730058e-01],\n",
       "        [ 8.09027289e-01,  2.18753631e-01, -3.47017570e-01,\n",
       "         -4.26256631e-02, -2.36435171e-01, -6.70953988e-02,\n",
       "          3.52461032e-03, -4.43036698e-02, -2.57821744e-01,\n",
       "          1.74750061e-02,  2.15005828e-01],\n",
       "        [-1.66508650e-02, -1.21170828e-01, -1.21816291e-01,\n",
       "          1.37159363e-01, -4.92864945e-01, -7.35181019e-04,\n",
       "          5.77826337e-01, -4.04267375e-01,  2.93844133e-01,\n",
       "         -2.54087841e-01, -2.45462203e-01],\n",
       "        [ 1.82049384e-02,  1.85239308e-04, -2.70097321e-01,\n",
       "         -5.16975507e-01,  2.36671226e-01, -5.11050900e-01,\n",
       "          3.43814694e-01,  2.75427423e-01,  3.25533621e-01,\n",
       "          1.89175447e-01, -8.02354041e-02],\n",
       "        [-3.34281926e-02, -6.34914852e-03,  3.75991405e-01,\n",
       "         -6.36296152e-01, -3.61448535e-01,  3.97237008e-01,\n",
       "          1.45062134e-01,  3.17995574e-02,  1.46378839e-02,\n",
       "          1.39741663e-01,  3.49801938e-01]]))"
      ]
     },
     "execution_count": 57,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "np.linalg.eig(H)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7bcda724",
   "metadata": {},
   "source": [
    "## Training"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "id": "8e92b57c",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Iteration: 1, Rollouts: 200, Reward: 54.30934128157487, Alpha: 1, Samples: 100\n",
      "Iteration: 2, Rollouts: 400, Reward: 101.30230492081712, Alpha: 1, Samples: 100\n",
      "Iteration: 3, Rollouts: 600, Reward: 91.7750724063481, Alpha: 1, Samples: 100\n",
      "Iteration: 4, Rollouts: 800, Reward: 128.96629614882036, Alpha: 1, Samples: 100\n",
      "Iteration: 5, Rollouts: 1000, Reward: 101.51074985723784, Alpha: 1, Samples: 100\n",
      "Iteration: 6, Rollouts: 1200, Reward: 101.34323810119672, Alpha: 1, Samples: 100\n",
      "Iteration: 7, Rollouts: 1400, Reward: 101.06793244325972, Alpha: 1, Samples: 100\n",
      "Iteration: 8, Rollouts: 1600, Reward: 101.1731966117439, Alpha: 1, Samples: 100\n",
      "Iteration: 9, Rollouts: 1800, Reward: 101.26107964750899, Alpha: 1, Samples: 100\n",
      "Iteration: 10, Rollouts: 2000, Reward: 101.0694330741772, Alpha: 1, Samples: 100\n",
      "Iteration: 11, Rollouts: 2200, Reward: 101.0230435733484, Alpha: 1, Samples: 100\n",
      "Iteration: 12, Rollouts: 2400, Reward: 101.31394919551505, Alpha: 1, Samples: 100\n",
      "Iteration: 13, Rollouts: 2600, Reward: 119.83853696870717, Alpha: 1, Samples: 100\n",
      "Iteration: 14, Rollouts: 2800, Reward: 91.95191518320874, Alpha: 1, Samples: 100\n",
      "Iteration: 15, Rollouts: 3000, Reward: 100.96701255595295, Alpha: 1, Samples: 100\n",
      "Iteration: 16, Rollouts: 3200, Reward: 91.82483010503049, Alpha: 1, Samples: 100\n",
      "Iteration: 17, Rollouts: 3400, Reward: 92.19309271121594, Alpha: 1, Samples: 100\n",
      "Iteration: 18, Rollouts: 3600, Reward: 91.5964295433587, Alpha: 1, Samples: 100\n",
      "Iteration: 19, Rollouts: 3800, Reward: 91.62117694058696, Alpha: 1, Samples: 100\n",
      "Iteration: 20, Rollouts: 4000, Reward: 101.12117029473706, Alpha: 1, Samples: 100\n",
      "Iteration: 21, Rollouts: 4200, Reward: 82.78439598340606, Alpha: 1, Samples: 100\n",
      "Iteration: 22, Rollouts: 4400, Reward: 82.6235152548191, Alpha: 1, Samples: 100\n",
      "Iteration: 23, Rollouts: 4600, Reward: 100.90583578897908, Alpha: 1, Samples: 100\n",
      "Iteration: 24, Rollouts: 4800, Reward: 82.57957035507454, Alpha: 1, Samples: 100\n",
      "Iteration: 25, Rollouts: 5000, Reward: 101.1305542694262, Alpha: 1, Samples: 100\n",
      "Iteration: 26, Rollouts: 5200, Reward: 119.91413888236337, Alpha: 1, Samples: 100\n",
      "Iteration: 27, Rollouts: 5400, Reward: 101.4910610140951, Alpha: 1, Samples: 100\n",
      "Iteration: 28, Rollouts: 5600, Reward: 101.01575808064993, Alpha: 1, Samples: 100\n",
      "Iteration: 29, Rollouts: 5800, Reward: 119.73594020832337, Alpha: 1, Samples: 100\n",
      "Iteration: 30, Rollouts: 6000, Reward: 100.94752942012795, Alpha: 1, Samples: 100\n",
      "Iteration: 31, Rollouts: 6200, Reward: 119.83886424951825, Alpha: 1, Samples: 100\n",
      "Iteration: 32, Rollouts: 6400, Reward: 129.07967369610608, Alpha: 1, Samples: 100\n",
      "Iteration: 33, Rollouts: 6600, Reward: 92.15561667915884, Alpha: 1, Samples: 100\n",
      "Iteration: 34, Rollouts: 6800, Reward: 110.25192550299425, Alpha: 1, Samples: 100\n",
      "Iteration: 35, Rollouts: 7000, Reward: 92.1848288048662, Alpha: 1, Samples: 100\n",
      "Iteration: 36, Rollouts: 7200, Reward: 91.58637942600178, Alpha: 1, Samples: 100\n",
      "Iteration: 37, Rollouts: 7400, Reward: 92.11720593240348, Alpha: 1, Samples: 100\n",
      "Iteration: 38, Rollouts: 7600, Reward: 91.58272695872017, Alpha: 1, Samples: 100\n",
      "Iteration: 39, Rollouts: 7800, Reward: 91.62103835208379, Alpha: 1, Samples: 100\n",
      "Iteration: 40, Rollouts: 8000, Reward: 110.48531861005846, Alpha: 1, Samples: 100\n",
      "Iteration: 41, Rollouts: 8200, Reward: 110.36884802532154, Alpha: 1, Samples: 100\n",
      "Iteration: 42, Rollouts: 8400, Reward: 101.37154618906537, Alpha: 1, Samples: 100\n",
      "Iteration: 43, Rollouts: 8600, Reward: 91.82141364669488, Alpha: 1, Samples: 100\n",
      "Iteration: 44, Rollouts: 8800, Reward: 119.84033876703135, Alpha: 1, Samples: 100\n",
      "Iteration: 45, Rollouts: 9000, Reward: 101.34490642006259, Alpha: 1, Samples: 100\n",
      "Iteration: 46, Rollouts: 9200, Reward: 91.97218209090202, Alpha: 1, Samples: 100\n",
      "Iteration: 47, Rollouts: 9400, Reward: 138.11734867653337, Alpha: 1, Samples: 100\n",
      "Iteration: 48, Rollouts: 9600, Reward: 129.13514739063228, Alpha: 1, Samples: 100\n",
      "Iteration: 49, Rollouts: 9800, Reward: 91.77273011485674, Alpha: 1, Samples: 100\n",
      "Iteration: 50, Rollouts: 10000, Reward: 110.70756541678756, Alpha: 1, Samples: 100\n",
      "Iteration: 51, Rollouts: 10200, Reward: 100.94516233065835, Alpha: 1, Samples: 100\n",
      "Iteration: 52, Rollouts: 10400, Reward: 91.78919385500198, Alpha: 1, Samples: 100\n",
      "Iteration: 53, Rollouts: 10600, Reward: 91.75914127348261, Alpha: 1, Samples: 100\n",
      "Iteration: 54, Rollouts: 10800, Reward: 119.85322326980463, Alpha: 1, Samples: 100\n",
      "Iteration: 55, Rollouts: 11000, Reward: 119.56780859838578, Alpha: 1, Samples: 100\n",
      "Iteration: 56, Rollouts: 11200, Reward: 119.67191508211661, Alpha: 1, Samples: 100\n",
      "Iteration: 57, Rollouts: 11400, Reward: 110.69688098191938, Alpha: 1, Samples: 100\n",
      "Iteration: 58, Rollouts: 11600, Reward: 128.995510775696, Alpha: 1, Samples: 100\n",
      "Iteration: 59, Rollouts: 11800, Reward: 110.34717714132307, Alpha: 1, Samples: 100\n",
      "Iteration: 60, Rollouts: 12000, Reward: 101.43582984528992, Alpha: 1, Samples: 100\n",
      "Iteration: 61, Rollouts: 12200, Reward: 164.83160690102218, Alpha: 1, Samples: 100\n",
      "Iteration: 62, Rollouts: 12400, Reward: 147.46258837600232, Alpha: 1, Samples: 100\n",
      "Iteration: 63, Rollouts: 12600, Reward: 154.99318202052362, Alpha: 1, Samples: 100\n",
      "Iteration: 64, Rollouts: 12800, Reward: 147.1000892283016, Alpha: 1, Samples: 100\n",
      "Iteration: 65, Rollouts: 13000, Reward: 166.34155372177983, Alpha: 1, Samples: 100\n",
      "Iteration: 66, Rollouts: 13200, Reward: 110.44689440204834, Alpha: 1, Samples: 100\n",
      "Iteration: 67, Rollouts: 13400, Reward: 229.74361043037422, Alpha: 1, Samples: 100\n",
      "Iteration: 68, Rollouts: 13600, Reward: 101.23569230259875, Alpha: 1, Samples: 100\n",
      "Iteration: 69, Rollouts: 13800, Reward: 136.87265247000713, Alpha: 1, Samples: 100\n",
      "Iteration: 70, Rollouts: 14000, Reward: 164.03091764188287, Alpha: 1, Samples: 100\n",
      "Iteration: 71, Rollouts: 14200, Reward: 119.6251202171252, Alpha: 1, Samples: 100\n",
      "Iteration: 72, Rollouts: 14400, Reward: 110.49737143315694, Alpha: 1, Samples: 100\n",
      "Iteration: 73, Rollouts: 14600, Reward: 201.58311478245906, Alpha: 1, Samples: 100\n",
      "Iteration: 74, Rollouts: 14800, Reward: 201.17763582906082, Alpha: 1, Samples: 100\n",
      "Iteration: 75, Rollouts: 15000, Reward: 239.25312553097712, Alpha: 1, Samples: 100\n",
      "Iteration: 76, Rollouts: 15200, Reward: 154.8858706417678, Alpha: 1, Samples: 100\n",
      "Iteration: 77, Rollouts: 15400, Reward: 258.9178518760544, Alpha: 1, Samples: 100\n",
      "Iteration: 78, Rollouts: 15600, Reward: 136.05686041055625, Alpha: 1, Samples: 100\n",
      "Iteration: 79, Rollouts: 15800, Reward: 146.9203818419632, Alpha: 1, Samples: 100\n",
      "Iteration: 80, Rollouts: 16000, Reward: 147.20036160775533, Alpha: 1, Samples: 100\n",
      "Iteration: 81, Rollouts: 16200, Reward: 184.3749288417094, Alpha: 1, Samples: 100\n",
      "Iteration: 82, Rollouts: 16400, Reward: 156.60940842123125, Alpha: 1, Samples: 100\n",
      "Iteration: 83, Rollouts: 16600, Reward: 135.79655918098467, Alpha: 1, Samples: 100\n",
      "Iteration: 84, Rollouts: 16800, Reward: 165.29208929842747, Alpha: 1, Samples: 100\n",
      "Iteration: 85, Rollouts: 17000, Reward: 166.23687436095446, Alpha: 1, Samples: 100\n",
      "Iteration: 86, Rollouts: 17200, Reward: 211.68690602628385, Alpha: 1, Samples: 100\n",
      "Iteration: 87, Rollouts: 17400, Reward: 100.7119889302815, Alpha: 1, Samples: 100\n",
      "Iteration: 88, Rollouts: 17600, Reward: 100.71119383255606, Alpha: 1, Samples: 100\n",
      "Iteration: 89, Rollouts: 17800, Reward: 135.92289636911613, Alpha: 1, Samples: 100\n",
      "Iteration: 90, Rollouts: 18000, Reward: 101.14410665160898, Alpha: 1, Samples: 100\n",
      "Iteration: 91, Rollouts: 18200, Reward: 119.69985202847235, Alpha: 1, Samples: 100\n",
      "Iteration: 92, Rollouts: 18400, Reward: 120.05579486383147, Alpha: 1, Samples: 100\n",
      "Iteration: 93, Rollouts: 18600, Reward: 171.71894575303918, Alpha: 1, Samples: 100\n",
      "Iteration: 94, Rollouts: 18800, Reward: 138.3313783830116, Alpha: 1, Samples: 100\n",
      "Iteration: 95, Rollouts: 19000, Reward: 129.08696963205836, Alpha: 1, Samples: 100\n",
      "Iteration: 96, Rollouts: 19200, Reward: 129.08064895787626, Alpha: 1, Samples: 100\n",
      "Iteration: 97, Rollouts: 19400, Reward: 136.30971035315247, Alpha: 1, Samples: 100\n",
      "Iteration: 98, Rollouts: 19600, Reward: 174.13314658302417, Alpha: 1, Samples: 100\n",
      "Iteration: 99, Rollouts: 19800, Reward: 202.4622570627284, Alpha: 1, Samples: 100\n",
      "Iteration: 100, Rollouts: 20000, Reward: 249.17770959781404, Alpha: 1, Samples: 100\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Iteration: 101, Rollouts: 20200, Reward: 221.56803263411192, Alpha: 1, Samples: 100\n",
      "Iteration: 102, Rollouts: 20400, Reward: 203.47345005635503, Alpha: 1, Samples: 100\n",
      "Iteration: 103, Rollouts: 20600, Reward: 165.72430509602086, Alpha: 1, Samples: 100\n",
      "Iteration: 104, Rollouts: 20800, Reward: 119.96948892379527, Alpha: 1, Samples: 100\n",
      "Iteration: 105, Rollouts: 21000, Reward: 120.05134239761276, Alpha: 1, Samples: 100\n",
      "Iteration: 106, Rollouts: 21200, Reward: 129.3057430476964, Alpha: 1, Samples: 100\n",
      "Iteration: 107, Rollouts: 21400, Reward: 101.39073693255773, Alpha: 1, Samples: 100\n",
      "Iteration: 108, Rollouts: 21600, Reward: 101.18961777543147, Alpha: 1, Samples: 100\n",
      "Iteration: 109, Rollouts: 21800, Reward: 92.03082122988293, Alpha: 1, Samples: 100\n",
      "Iteration: 110, Rollouts: 22000, Reward: 257.7333726821944, Alpha: 1, Samples: 100\n",
      "Iteration: 111, Rollouts: 22200, Reward: 101.48411471873861, Alpha: 1, Samples: 100\n",
      "Iteration: 112, Rollouts: 22400, Reward: 129.00897592794925, Alpha: 1, Samples: 100\n",
      "Iteration: 113, Rollouts: 22600, Reward: 92.02215451824847, Alpha: 1, Samples: 100\n",
      "Iteration: 114, Rollouts: 22800, Reward: 91.78993174385032, Alpha: 1, Samples: 100\n",
      "Iteration: 115, Rollouts: 23000, Reward: 127.696874493715, Alpha: 1, Samples: 100\n",
      "Iteration: 116, Rollouts: 23200, Reward: 101.29349560036353, Alpha: 1, Samples: 100\n",
      "Iteration: 117, Rollouts: 23400, Reward: 110.72917513118308, Alpha: 1, Samples: 100\n",
      "Iteration: 118, Rollouts: 23600, Reward: 129.22618147772334, Alpha: 1, Samples: 100\n",
      "Iteration: 119, Rollouts: 23800, Reward: 110.51112175996118, Alpha: 1, Samples: 100\n",
      "Iteration: 120, Rollouts: 24000, Reward: 128.72542670365357, Alpha: 1, Samples: 100\n",
      "Iteration: 121, Rollouts: 24200, Reward: 101.38538021321665, Alpha: 1, Samples: 100\n",
      "Iteration: 122, Rollouts: 24400, Reward: 110.41510075422568, Alpha: 1, Samples: 100\n",
      "Iteration: 123, Rollouts: 24600, Reward: 147.49861719579874, Alpha: 1, Samples: 100\n",
      "Iteration: 124, Rollouts: 24800, Reward: 110.295606990032, Alpha: 1, Samples: 100\n",
      "Iteration: 125, Rollouts: 25000, Reward: 192.81896937014997, Alpha: 1, Samples: 100\n",
      "Iteration: 126, Rollouts: 25200, Reward: 192.653914435795, Alpha: 1, Samples: 100\n",
      "Iteration: 127, Rollouts: 25400, Reward: 147.56166308318268, Alpha: 1, Samples: 100\n",
      "Iteration: 128, Rollouts: 25600, Reward: 138.18006008019177, Alpha: 1, Samples: 100\n",
      "Iteration: 129, Rollouts: 25800, Reward: 147.84734202149127, Alpha: 1, Samples: 100\n",
      "Iteration: 130, Rollouts: 26000, Reward: 147.96715416809556, Alpha: 1, Samples: 100\n",
      "Iteration: 131, Rollouts: 26200, Reward: 91.95456255200733, Alpha: 1, Samples: 100\n",
      "Iteration: 132, Rollouts: 26400, Reward: 193.2125800742105, Alpha: 1, Samples: 100\n",
      "Iteration: 133, Rollouts: 26600, Reward: 136.98619723333258, Alpha: 1, Samples: 100\n",
      "Iteration: 134, Rollouts: 26800, Reward: 101.19660083160059, Alpha: 1, Samples: 100\n",
      "Iteration: 135, Rollouts: 27000, Reward: 119.89638500296365, Alpha: 1, Samples: 100\n",
      "Iteration: 136, Rollouts: 27200, Reward: 183.88712316609246, Alpha: 1, Samples: 100\n",
      "Iteration: 137, Rollouts: 27400, Reward: 138.5423286873263, Alpha: 1, Samples: 100\n",
      "Iteration: 138, Rollouts: 27600, Reward: 128.67924397288417, Alpha: 1, Samples: 100\n",
      "Iteration: 139, Rollouts: 27800, Reward: 184.09834942589072, Alpha: 1, Samples: 100\n",
      "Iteration: 140, Rollouts: 28000, Reward: 147.6782225649547, Alpha: 1, Samples: 100\n",
      "Iteration: 141, Rollouts: 28200, Reward: 172.69141429636926, Alpha: 1, Samples: 100\n",
      "Iteration: 142, Rollouts: 28400, Reward: 220.77046783488106, Alpha: 1, Samples: 100\n",
      "Iteration: 143, Rollouts: 28600, Reward: 119.47956346070768, Alpha: 1, Samples: 100\n",
      "Iteration: 144, Rollouts: 28800, Reward: 211.39826169122892, Alpha: 1, Samples: 100\n",
      "Iteration: 145, Rollouts: 29000, Reward: 147.72999028273853, Alpha: 1, Samples: 100\n",
      "Iteration: 146, Rollouts: 29200, Reward: 239.17572726057637, Alpha: 1, Samples: 100\n",
      "Iteration: 147, Rollouts: 29400, Reward: 184.60778171937523, Alpha: 1, Samples: 100\n",
      "Iteration: 148, Rollouts: 29600, Reward: 166.13573182363902, Alpha: 1, Samples: 100\n",
      "Iteration: 149, Rollouts: 29800, Reward: 129.00467284785088, Alpha: 1, Samples: 100\n",
      "Iteration: 150, Rollouts: 30000, Reward: 147.6939966259643, Alpha: 1, Samples: 100\n",
      "Iteration: 151, Rollouts: 30200, Reward: 101.21015758653647, Alpha: 1, Samples: 100\n",
      "Iteration: 152, Rollouts: 30400, Reward: 199.03065009713632, Alpha: 1, Samples: 100\n",
      "Iteration: 153, Rollouts: 30600, Reward: 137.72977090951773, Alpha: 1, Samples: 100\n",
      "Iteration: 154, Rollouts: 30800, Reward: 156.60875010580685, Alpha: 1, Samples: 100\n",
      "Iteration: 155, Rollouts: 31000, Reward: 258.66412039245597, Alpha: 1, Samples: 100\n",
      "Iteration: 156, Rollouts: 31200, Reward: 110.10084380086252, Alpha: 1, Samples: 100\n",
      "Iteration: 157, Rollouts: 31400, Reward: 236.9937763901658, Alpha: 1, Samples: 100\n",
      "Iteration: 158, Rollouts: 31600, Reward: 192.15229565724084, Alpha: 1, Samples: 100\n",
      "Iteration: 159, Rollouts: 31800, Reward: 137.2496298967551, Alpha: 1, Samples: 100\n",
      "Iteration: 160, Rollouts: 32000, Reward: 194.09071111255037, Alpha: 1, Samples: 100\n",
      "Iteration: 161, Rollouts: 32200, Reward: 211.26527850409695, Alpha: 1, Samples: 100\n",
      "Iteration: 162, Rollouts: 32400, Reward: 247.87804551471126, Alpha: 1, Samples: 100\n",
      "Iteration: 163, Rollouts: 32600, Reward: 174.99963799944487, Alpha: 1, Samples: 100\n",
      "Iteration: 164, Rollouts: 32800, Reward: 173.44958987523154, Alpha: 1, Samples: 100\n",
      "Iteration: 165, Rollouts: 33000, Reward: 156.18971518775314, Alpha: 1, Samples: 100\n",
      "Iteration: 166, Rollouts: 33200, Reward: 110.36808994063945, Alpha: 1, Samples: 100\n",
      "Iteration: 167, Rollouts: 33400, Reward: 136.50526271063418, Alpha: 1, Samples: 100\n",
      "Iteration: 168, Rollouts: 33600, Reward: 157.08349393470544, Alpha: 1, Samples: 100\n",
      "Iteration: 169, Rollouts: 33800, Reward: 231.41507828784376, Alpha: 1, Samples: 100\n",
      "Iteration: 170, Rollouts: 34000, Reward: 249.13636547710925, Alpha: 1, Samples: 100\n",
      "Iteration: 171, Rollouts: 34200, Reward: 101.33595805042013, Alpha: 1, Samples: 100\n",
      "Iteration: 172, Rollouts: 34400, Reward: 210.42891701457611, Alpha: 1, Samples: 100\n",
      "Iteration: 173, Rollouts: 34600, Reward: 165.61384540837958, Alpha: 1, Samples: 100\n",
      "Iteration: 174, Rollouts: 34800, Reward: 163.0186409889366, Alpha: 1, Samples: 100\n",
      "Iteration: 175, Rollouts: 35000, Reward: 221.21291693494447, Alpha: 1, Samples: 100\n",
      "Iteration: 176, Rollouts: 35200, Reward: 129.14869947191417, Alpha: 1, Samples: 100\n",
      "Iteration: 177, Rollouts: 35400, Reward: 211.3920003574162, Alpha: 1, Samples: 100\n",
      "Iteration: 178, Rollouts: 35600, Reward: 129.03836590637948, Alpha: 1, Samples: 100\n",
      "Iteration: 179, Rollouts: 35800, Reward: 304.9021892502109, Alpha: 1, Samples: 100\n",
      "Iteration: 180, Rollouts: 36000, Reward: 193.1963861743174, Alpha: 1, Samples: 100\n",
      "Iteration: 181, Rollouts: 36200, Reward: 135.61230714170475, Alpha: 1, Samples: 100\n",
      "Iteration: 182, Rollouts: 36400, Reward: 119.71829014225723, Alpha: 1, Samples: 100\n",
      "Iteration: 183, Rollouts: 36600, Reward: 304.6591786898472, Alpha: 1, Samples: 100\n",
      "Iteration: 184, Rollouts: 36800, Reward: 128.55016611704437, Alpha: 1, Samples: 100\n",
      "Iteration: 185, Rollouts: 37000, Reward: 219.98737296871624, Alpha: 1, Samples: 100\n",
      "Iteration: 186, Rollouts: 37200, Reward: 156.9046005081585, Alpha: 1, Samples: 100\n",
      "Iteration: 187, Rollouts: 37400, Reward: 192.65384385870342, Alpha: 1, Samples: 100\n",
      "Iteration: 188, Rollouts: 37600, Reward: 129.2652967886717, Alpha: 1, Samples: 100\n",
      "Iteration: 189, Rollouts: 37800, Reward: 119.74491263232878, Alpha: 1, Samples: 100\n",
      "Iteration: 190, Rollouts: 38000, Reward: 119.69146844735184, Alpha: 1, Samples: 100\n",
      "Iteration: 191, Rollouts: 38200, Reward: 182.7944262039976, Alpha: 1, Samples: 100\n",
      "Iteration: 192, Rollouts: 38400, Reward: 119.71578740880206, Alpha: 1, Samples: 100\n",
      "Iteration: 193, Rollouts: 38600, Reward: 155.7036260069994, Alpha: 1, Samples: 100\n",
      "Iteration: 194, Rollouts: 38800, Reward: 128.12016822456025, Alpha: 1, Samples: 100\n",
      "Iteration: 195, Rollouts: 39000, Reward: 332.11881614625287, Alpha: 1, Samples: 100\n",
      "Iteration: 196, Rollouts: 39200, Reward: 203.20452002916159, Alpha: 1, Samples: 100\n",
      "Iteration: 197, Rollouts: 39400, Reward: 146.73101087647052, Alpha: 1, Samples: 100\n",
      "Iteration: 198, Rollouts: 39600, Reward: 110.61277389890498, Alpha: 1, Samples: 100\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Iteration: 199, Rollouts: 39800, Reward: 138.29144282649102, Alpha: 1, Samples: 100\n",
      "Iteration: 200, Rollouts: 40000, Reward: 166.23092596725434, Alpha: 1, Samples: 100\n",
      "Iteration: 201, Rollouts: 40200, Reward: 155.7413063864278, Alpha: 1, Samples: 100\n",
      "Iteration: 202, Rollouts: 40400, Reward: 212.32930515095774, Alpha: 1, Samples: 100\n",
      "Iteration: 203, Rollouts: 40600, Reward: 201.4172977000889, Alpha: 1, Samples: 100\n",
      "Iteration: 204, Rollouts: 40800, Reward: 184.0476688101044, Alpha: 1, Samples: 100\n",
      "Iteration: 205, Rollouts: 41000, Reward: 183.99281765008746, Alpha: 1, Samples: 100\n",
      "Iteration: 206, Rollouts: 41200, Reward: 193.26142017146327, Alpha: 1, Samples: 100\n",
      "Iteration: 207, Rollouts: 41400, Reward: 146.9803807293929, Alpha: 1, Samples: 100\n",
      "Iteration: 208, Rollouts: 41600, Reward: 183.30733978707124, Alpha: 1, Samples: 100\n",
      "Iteration: 209, Rollouts: 41800, Reward: 156.1161128252999, Alpha: 1, Samples: 100\n",
      "Iteration: 210, Rollouts: 42000, Reward: 257.40956783022614, Alpha: 1, Samples: 100\n",
      "Iteration: 211, Rollouts: 42200, Reward: 209.10624610011504, Alpha: 1, Samples: 100\n",
      "Iteration: 212, Rollouts: 42400, Reward: 201.78387922845963, Alpha: 1, Samples: 100\n",
      "Iteration: 213, Rollouts: 42600, Reward: 193.39429932822478, Alpha: 1, Samples: 100\n",
      "Iteration: 214, Rollouts: 42800, Reward: 342.4887377875453, Alpha: 1, Samples: 100\n",
      "Iteration: 215, Rollouts: 43000, Reward: 340.1354579673932, Alpha: 1, Samples: 100\n",
      "Iteration: 216, Rollouts: 43200, Reward: 193.13139806662295, Alpha: 1, Samples: 100\n",
      "Iteration: 217, Rollouts: 43400, Reward: 268.3768442454858, Alpha: 1, Samples: 100\n",
      "Iteration: 218, Rollouts: 43600, Reward: 416.7002215649075, Alpha: 1, Samples: 100\n",
      "Iteration: 219, Rollouts: 43800, Reward: 183.11695895556463, Alpha: 1, Samples: 100\n",
      "Iteration: 220, Rollouts: 44000, Reward: 166.24407168694847, Alpha: 1, Samples: 100\n",
      "Iteration: 221, Rollouts: 44200, Reward: 202.3441408252062, Alpha: 1, Samples: 100\n",
      "Iteration: 222, Rollouts: 44400, Reward: 174.2053205310669, Alpha: 1, Samples: 100\n",
      "Iteration: 223, Rollouts: 44600, Reward: 184.27453736715998, Alpha: 1, Samples: 100\n",
      "Iteration: 224, Rollouts: 44800, Reward: 267.19712018997353, Alpha: 1, Samples: 100\n",
      "Iteration: 225, Rollouts: 45000, Reward: 119.72125964633769, Alpha: 1, Samples: 100\n",
      "Iteration: 226, Rollouts: 45200, Reward: 200.35791809578552, Alpha: 1, Samples: 100\n",
      "Iteration: 227, Rollouts: 45400, Reward: 257.6183206086012, Alpha: 1, Samples: 100\n",
      "Iteration: 228, Rollouts: 45600, Reward: 237.60554462231468, Alpha: 1, Samples: 100\n",
      "Iteration: 229, Rollouts: 45800, Reward: 240.3280321560731, Alpha: 1, Samples: 100\n",
      "Iteration: 230, Rollouts: 46000, Reward: 220.13202905279087, Alpha: 1, Samples: 100\n",
      "Iteration: 231, Rollouts: 46200, Reward: 229.8820620128118, Alpha: 1, Samples: 100\n",
      "Iteration: 232, Rollouts: 46400, Reward: 209.09328359212395, Alpha: 1, Samples: 100\n",
      "Iteration: 233, Rollouts: 46600, Reward: 101.1699211091612, Alpha: 1, Samples: 100\n",
      "Iteration: 234, Rollouts: 46800, Reward: 193.30285404536045, Alpha: 1, Samples: 100\n",
      "Iteration: 235, Rollouts: 47000, Reward: 190.0646298946485, Alpha: 1, Samples: 100\n",
      "Iteration: 236, Rollouts: 47200, Reward: 248.73566208221962, Alpha: 1, Samples: 100\n",
      "Iteration: 237, Rollouts: 47400, Reward: 201.2955924757842, Alpha: 1, Samples: 100\n",
      "Iteration: 238, Rollouts: 47600, Reward: 199.88900106468654, Alpha: 1, Samples: 100\n",
      "Iteration: 239, Rollouts: 47800, Reward: 101.0447503231941, Alpha: 1, Samples: 100\n",
      "Iteration: 240, Rollouts: 48000, Reward: 172.5094839180714, Alpha: 1, Samples: 100\n",
      "Iteration: 241, Rollouts: 48200, Reward: 190.84384200775241, Alpha: 1, Samples: 100\n",
      "Iteration: 242, Rollouts: 48400, Reward: 192.26715451644336, Alpha: 1, Samples: 100\n",
      "Iteration: 243, Rollouts: 48600, Reward: 294.8541240570784, Alpha: 1, Samples: 100\n",
      "Iteration: 244, Rollouts: 48800, Reward: 193.16959663671508, Alpha: 1, Samples: 100\n",
      "Iteration: 245, Rollouts: 49000, Reward: 128.89448465288274, Alpha: 1, Samples: 100\n",
      "Iteration: 246, Rollouts: 49200, Reward: 219.51851352556054, Alpha: 1, Samples: 100\n",
      "Iteration: 247, Rollouts: 49400, Reward: 220.96628269842438, Alpha: 1, Samples: 100\n",
      "Iteration: 248, Rollouts: 49600, Reward: 119.60050754305789, Alpha: 1, Samples: 100\n",
      "Iteration: 249, Rollouts: 49800, Reward: 155.04934889082767, Alpha: 1, Samples: 100\n",
      "Iteration: 250, Rollouts: 50000, Reward: 128.98941090733138, Alpha: 1, Samples: 100\n",
      "Iteration: 251, Rollouts: 50200, Reward: 248.35151757060117, Alpha: 1, Samples: 100\n",
      "Iteration: 252, Rollouts: 50400, Reward: 164.6238740751158, Alpha: 1, Samples: 100\n",
      "Iteration: 253, Rollouts: 50600, Reward: 147.89136205072032, Alpha: 1, Samples: 100\n",
      "Iteration: 254, Rollouts: 50800, Reward: 211.89248587862596, Alpha: 1, Samples: 100\n",
      "Iteration: 255, Rollouts: 51000, Reward: 375.4164733537801, Alpha: 1, Samples: 100\n",
      "Iteration: 256, Rollouts: 51200, Reward: 110.66295734334126, Alpha: 1, Samples: 100\n",
      "Iteration: 257, Rollouts: 51400, Reward: 155.7516968444825, Alpha: 1, Samples: 100\n",
      "Iteration: 258, Rollouts: 51600, Reward: 138.3777205699429, Alpha: 1, Samples: 100\n",
      "Iteration: 259, Rollouts: 51800, Reward: 165.91136013421047, Alpha: 1, Samples: 100\n",
      "Iteration: 260, Rollouts: 52000, Reward: 229.1070676841368, Alpha: 1, Samples: 100\n",
      "Iteration: 261, Rollouts: 52200, Reward: 184.4254436836232, Alpha: 1, Samples: 100\n",
      "Iteration: 262, Rollouts: 52400, Reward: 119.85652488861673, Alpha: 1, Samples: 100\n",
      "Iteration: 263, Rollouts: 52600, Reward: 314.6352960583398, Alpha: 1, Samples: 100\n",
      "Iteration: 264, Rollouts: 52800, Reward: 284.3857249058312, Alpha: 1, Samples: 100\n",
      "Iteration: 265, Rollouts: 53000, Reward: 174.06473478244274, Alpha: 1, Samples: 100\n",
      "Iteration: 266, Rollouts: 53200, Reward: 157.1373477080749, Alpha: 1, Samples: 100\n",
      "Iteration: 267, Rollouts: 53400, Reward: 256.7139987641344, Alpha: 1, Samples: 100\n",
      "Iteration: 268, Rollouts: 53600, Reward: 221.83775612104935, Alpha: 1, Samples: 100\n",
      "Iteration: 269, Rollouts: 53800, Reward: 321.647670402125, Alpha: 1, Samples: 100\n",
      "Iteration: 270, Rollouts: 54000, Reward: 129.15542515414975, Alpha: 1, Samples: 100\n",
      "Iteration: 271, Rollouts: 54200, Reward: 156.7519334713111, Alpha: 1, Samples: 100\n",
      "Iteration: 272, Rollouts: 54400, Reward: 266.926077057398, Alpha: 1, Samples: 100\n",
      "Iteration: 273, Rollouts: 54600, Reward: 166.38866071861264, Alpha: 1, Samples: 100\n",
      "Iteration: 274, Rollouts: 54800, Reward: 210.83839902930632, Alpha: 1, Samples: 100\n",
      "Iteration: 275, Rollouts: 55000, Reward: 200.89354196148082, Alpha: 1, Samples: 100\n",
      "Iteration: 276, Rollouts: 55200, Reward: 110.5831530452548, Alpha: 1, Samples: 100\n",
      "Iteration: 277, Rollouts: 55400, Reward: 277.36741989674056, Alpha: 1, Samples: 100\n",
      "Iteration: 278, Rollouts: 55600, Reward: 138.0738581300165, Alpha: 1, Samples: 100\n",
      "Iteration: 279, Rollouts: 55800, Reward: 137.3306449635146, Alpha: 1, Samples: 100\n",
      "Iteration: 280, Rollouts: 56000, Reward: 164.5652775093798, Alpha: 1, Samples: 100\n",
      "Iteration: 281, Rollouts: 56200, Reward: 119.9692905727429, Alpha: 1, Samples: 100\n",
      "Iteration: 282, Rollouts: 56400, Reward: 246.2042086868219, Alpha: 1, Samples: 100\n",
      "Iteration: 283, Rollouts: 56600, Reward: 267.8698606073883, Alpha: 1, Samples: 100\n",
      "Iteration: 284, Rollouts: 56800, Reward: 285.0557585046443, Alpha: 1, Samples: 100\n",
      "Iteration: 285, Rollouts: 57000, Reward: 101.39365592715873, Alpha: 1, Samples: 100\n",
      "Iteration: 286, Rollouts: 57200, Reward: 119.4935196926431, Alpha: 1, Samples: 100\n",
      "Iteration: 287, Rollouts: 57400, Reward: 200.76782525155824, Alpha: 1, Samples: 100\n",
      "Iteration: 288, Rollouts: 57600, Reward: 119.67267257118294, Alpha: 1, Samples: 100\n",
      "Iteration: 289, Rollouts: 57800, Reward: 110.6390785710832, Alpha: 1, Samples: 100\n",
      "Iteration: 290, Rollouts: 58000, Reward: 119.77017862612476, Alpha: 1, Samples: 100\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-58-bb4389fbdcc9>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m     33\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     34\u001b[0m     \u001b[0mparams\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'n_iter'\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mn_iter\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 35\u001b[0;31m     \u001b[0mgradient\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mn_samples\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtimesteps\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mHinv\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mHessianES\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mparams\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmaster\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     36\u001b[0m     \u001b[0mHinv_success\u001b[0m \u001b[0;34m+=\u001b[0m \u001b[0mHinv\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     37\u001b[0m \u001b[0;31m#     print(Hinv)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m<ipython-input-36-8cdaa0b4c6bf>\u001b[0m in \u001b[0;36mHessianES\u001b[0;34m(params, master)\u001b[0m\n\u001b[1;32m     51\u001b[0m     \u001b[0mA\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mvstack\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mA\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmu\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;31m# Adding a reference evaluation\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     52\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 53\u001b[0;31m     \u001b[0mgradient_y\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mhessian_y\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtimesteps\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0maggregate_rollouts_hessianES\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmaster\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mA\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mparams\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mn_samples\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     54\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     55\u001b[0m     \u001b[0mg\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mGradient_LP\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mgradient_y\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mA\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m-\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m:\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m/\u001b[0m\u001b[0mparams\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m\"sigma\"\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m<ipython-input-36-8cdaa0b4c6bf>\u001b[0m in \u001b[0;36maggregate_rollouts_hessianES\u001b[0;34m(master, A, params, n_samples)\u001b[0m\n\u001b[1;32m      9\u001b[0m     \u001b[0;32mfor\u001b[0m \u001b[0mi\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mrange\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mn_samples\u001b[0m\u001b[0;34m+\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     10\u001b[0m         \u001b[0mw\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mworker\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mparams\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmaster\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mA\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mi\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 11\u001b[0;31m         \u001b[0mall_rollouts\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mi\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mreshape\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mw\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdo_rollouts\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m2\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     12\u001b[0m         \u001b[0mtimesteps\u001b[0m \u001b[0;34m+=\u001b[0m \u001b[0mw\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtimesteps\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     13\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/Users/stevenyin/Google Drive/columbia/semester 9/krzysztof class/Project6617/asebo/worker.py\u001b[0m in \u001b[0;36mdo_rollouts\u001b[0;34m(self, seed, train)\u001b[0m\n\u001b[1;32m     34\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     35\u001b[0m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpolicy\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mupdate\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mv\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 36\u001b[0;31m         \u001b[0mup\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mrollout\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mseed\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtrain\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     37\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     38\u001b[0m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpolicy\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mupdate\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m-\u001b[0m\u001b[0;36m2\u001b[0m \u001b[0;34m*\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mv\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/Users/stevenyin/Google Drive/columbia/semester 9/krzysztof class/Project6617/asebo/worker.py\u001b[0m in \u001b[0;36mrollout\u001b[0;34m(self, seed, train, render)\u001b[0m\n\u001b[1;32m     49\u001b[0m         \u001b[0;32mwhile\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0mdone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     50\u001b[0m             \u001b[0maction\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpolicy\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mevaluate\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mstate\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 51\u001b[0;31m             \u001b[0maction\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mclip\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0maction\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0menv\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0maction_space\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mlow\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0menv\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0maction_space\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mhigh\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     52\u001b[0m             \u001b[0maction\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0maction\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mreshape\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mlen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0maction\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     53\u001b[0m             \u001b[0mstate\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mreward\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdone\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0m_\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0menv\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mstep\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0maction\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m<__array_function__ internals>\u001b[0m in \u001b[0;36mclip\u001b[0;34m(*args, **kwargs)\u001b[0m\n",
      "\u001b[0;32m/Users/stevenyin/opt/anaconda3/envs/py36/lib/python3.6/site-packages/numpy/core/fromnumeric.py\u001b[0m in \u001b[0;36mclip\u001b[0;34m(a, a_min, a_max, out, **kwargs)\u001b[0m\n\u001b[1;32m   1972\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1973\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1974\u001b[0;31m \u001b[0;34m@\u001b[0m\u001b[0marray_function_dispatch\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0m_clip_dispatcher\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1975\u001b[0m \u001b[0;32mdef\u001b[0m \u001b[0mclip\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0ma\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0ma_min\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0ma_max\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mout\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mNone\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1976\u001b[0m     \"\"\"\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "# def run_hessianES(params):\n",
    "\n",
    "env = gym.make(params['env_name'])\n",
    "params['ob_dim'] = env.observation_space.shape[0]\n",
    "params['ac_dim'] = env.action_space.shape[0]\n",
    "\n",
    "m = 0\n",
    "v = 0\n",
    "\n",
    "params['k'] += -1\n",
    "params['alpha'] = 1\n",
    "\n",
    "params['zeros'] = False\n",
    "master = get_policy(params)\n",
    "\n",
    "if params['log']:\n",
    "    params['num_sensings'] = 4 + int(3 * np.log(master.N))\n",
    "\n",
    "if params['k'] > master.N:\n",
    "    params['k'] = master.N\n",
    "\n",
    "n_eps = 0\n",
    "n_iter = 1\n",
    "ts_cumulative = 0\n",
    "ts = []\n",
    "rollouts = []\n",
    "rewards = []\n",
    "samples = []\n",
    "alphas = []\n",
    "G = [] # Don't need this for HessianES\n",
    "Hinv_success = 0\n",
    "while n_iter < params['max_iter']:\n",
    "\n",
    "    params['n_iter'] = n_iter\n",
    "    gradient, n_samples, timesteps, Hinv = HessianES(params, master)\n",
    "    Hinv_success += Hinv\n",
    "#     print(Hinv)\n",
    "#     gradient, n_samples, timesteps = ES(params, master, G)\n",
    "    \n",
    "    ts_cumulative += timesteps\n",
    "    ts.append(ts_cumulative)\n",
    "    alphas.append(params['alpha'])\n",
    "\n",
    "    if n_iter == 1:\n",
    "        G = np.array(gradient)\n",
    "    else:\n",
    "        G *= params['decay']\n",
    "        G = np.vstack([G, gradient])\n",
    "    n_eps += 2 * n_samples\n",
    "    rollouts.append(n_eps)\n",
    "#     gradient /= (np.linalg.norm(gradient) / master.N + 1e-8)\n",
    "\n",
    "#     update, m, v = Adam(gradient, m, v, params['learning_rate'], n_iter)\n",
    "    update = params['learning_rate']*gradient\n",
    "\n",
    "    master.update(update)\n",
    "    test_policy = worker(params, master, np.zeros([1, master.N]), 0)\n",
    "    reward = test_policy.rollout(train=False)\n",
    "    rewards.append(reward)\n",
    "    samples.append(n_samples)\n",
    "\n",
    "    print('Iteration: %s, Rollouts: %s, Reward: %s, Alpha: %s, Samples: %s' %(n_iter, n_eps, reward, params['alpha'], n_samples))\n",
    "    n_iter += 1\n",
    "\n",
    "    out = pd.DataFrame({'Rollouts': rollouts, 'Reward': rewards, 'Samples': samples, 'Timesteps': ts, 'Alpha': alphas})\n",
    "    out.to_csv('HessianES_Seed%s.csv' %(params['seed']), index=False)     "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "id": "4d51b71f",
   "metadata": {},
   "outputs": [],
   "source": [
    "np.save(\"./data/{}_hessian.npy\".format(params['dir']), master.params)\n",
    "np.save(\"./data/{}_hessian_ts.npy\".format(params['dir']), ts)\n",
    "np.save(\"./data/{}_hessian_rs.npy\".format(params['dir']), rewards)\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "52ac9e4a",
   "metadata": {},
   "outputs": [],
   "source": [
    "asebo_ts = np.load(\"./data/InvertedPendulum-v2Toeplitz_h32_lr0.05_k140__asebo_ts.npy\")\n",
    "asebo_rewards = np.load(\"./data/InvertedPendulum-v2Toeplitz_h32_lr0.05_k140__asebo_rs.npy\")\n",
    "\n",
    "lpgrad_ts = np.load(\"./data/InvertedPendulum-v2Linear_h32_lr0.05_num_sensings100__LP_ts.npy\")\n",
    "lpgrad_rewards = np.load(\"./data/InvertedPendulum-v2Linear_h32_lr0.05_num_sensings100__LP_rs.npy\")\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1fddf3bb",
   "metadata": {},
   "outputs": [],
   "source": [
    "# plt.plot(asebo_ts, asebo_rewards, label=\"ASEBO\")\n",
    "# plt.plot(lpgrad_ts, lpgrad_rewards, label=\"LP gradient\")\n",
    "plt.plot(ts, rewards, label=\"LP Hessian\")\n",
    "plt.legend()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "345e7a36",
   "metadata": {},
   "source": [
    "# Testing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "id": "5d50cdec",
   "metadata": {},
   "outputs": [],
   "source": [
    "# master = get_policy(params)\n",
    "# master.params=np.load(\"./data/{}_hessian.npy\".format(params['dir']))\n",
    "test_policy = worker(params, master, np.zeros([1, master.N]), 0)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "id": "ea5c991e",
   "metadata": {},
   "outputs": [],
   "source": [
    "from gym.wrappers import Monitor\n",
    "env = Monitor(gym.make(params['env_name']), './video', force=True)\n",
    "env._max_episode_steps = params['steps']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "id": "15e95524",
   "metadata": {},
   "outputs": [],
   "source": [
    "def play(env, worker):\n",
    "    state = env.reset()\n",
    "    while 1:\n",
    "        action = worker.policy.evaluate(state)\n",
    "        action = np.clip(action, worker.env.action_space.low[0], worker.env.action_space.high[0])\n",
    "        action = action.reshape(len(action), )\n",
    "        state, reward, done, info = env.step(action)\n",
    "        env.render()\n",
    "        if done: \n",
    "            break"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "id": "f6e69ff4",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Creating offscreen glfw\n",
      "Creating window glfw\n"
     ]
    }
   ],
   "source": [
    "play(env, test_policy)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ef827e32",
   "metadata": {},
   "outputs": [],
   "source": [
    "len(ts)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bdffec34",
   "metadata": {},
   "outputs": [],
   "source": [
    "params['dir']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "33324ed5",
   "metadata": {},
   "outputs": [],
   "source": [
    "np.save(\"./data/{}_hessian_ts.npy\".format(params['dir']), ts)\n",
    "np.save(\"./data/{}_hessian_rs.npy\".format(params['dir']), rewards)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f44e2bb3",
   "metadata": {},
   "outputs": [],
   "source": [
    "sigma = 0.05\n",
    "# np.random.seed(0)\n",
    "# theta = np.random.uniform(-5,5,5)\n",
    "theta = 0.0 * np.ones(5)\n",
    "n = 100\n",
    "d = len(theta)\n",
    "\n",
    "print('theta:')\n",
    "print(theta)\n",
    "epsilons = np.random.multivariate_normal(mean = np.zeros(d), cov = np.identity(d), size = n)\n",
    "\n",
    "g = Gradient_LP(theta, sigma, epsilons)\n",
    "print('gradient:')\n",
    "print(g)\n",
    "\n",
    "H = Hessian_LP(theta, sigma, epsilons)\n",
    "print('Hessian:')\n",
    "print(H)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "07706f57",
   "metadata": {},
   "outputs": [],
   "source": [
    "!open .\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e4c5db78",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
